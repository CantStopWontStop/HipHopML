---
title: "HipHop ML"
title-slide-attributes:
    data-background-image: /imgs/hip-hop.png
    data-background-size: cover
    data-background-opacity: "0.5"
author: "def jam()"
date: 'Mar 7, 2023'
format: 
    revealjs:
        theme: [dark, custom.scss]
        toc: false
execute: 
  echo: false
  warning: false
  freeze: true
  
from: markdown+emoji
---

# Introduction {.sectionhead style="color:#222222"}

```{r}
source('functions.R')
library(reticulate)
```

## Producers

:radio: DJ [Joan]{.red} Adebowale

:musical_score: Lil [Marquesia]{.red} Atwater

:microphone: MC [Tesa]{.red} Childs-Skelton

:cd: Grand Master [Sorie]{.red} Dumbuya

:speaker: Ol' Dirty [Marcus]{.red} Gibson

## Tracklist {background-image="imgs/vinyl.jpg" background-size="cover"}

::: {.column .li_item width="80%"}
-   [Overview]{.red} -- Ol Dirty Marcus
-   [Data Processing]{.red} -- MC Tesa
-   [Machine Learning]{.red} -- Grandmaster Sorie
-   [Discussion]{.red} -- DJ Joan feat. Lil Marquesia
-   [Round of Applause]{.red} -- GT Bootcamp 2023 Cohort
:::

## Overview

-   In 2023, Hip hop will celebrate [the 50th anniversary](https://the50thanniversaryofhip-hop.com/){target="_blank"} of its founding by Brooklyn youth.

-   Since then, it has become a billion dollar industry and [the most popular music genre in the US](https://www.billboard.com/music/music-news/billboard-explains-rb-hip-hop-biggest-genre-9613422/#!).

## Challenge

-   Using machine learning and lyrics retrieved via the Genius API to identify songs hip hop and RnB based on lyrics

# Data Processing {.sectionhead style="color:#222222"}

## Data Sources

::: panel-tabset
## Songs

::: columns
::: {.column width="50%"}
[Scraped Wikipedia pages](analysis/rnb_wiki_scrapper.html) for Billboard's #1 Songs from 1989-2019 for:

-   Country

-   Hip hop

-   RnB

-   Rock
:::

::: {.column width="50%"}
![](imgs/wiki.png){fig-align="center" width="100%"}
:::
:::

## Database

::: columns
::: {.column width="50%"}
![](imgs/rds.png){fig-align="center" width="100%"}

:::

::: {.column width="50%"}
![](imgs/table.png){fig-align="center" width="100%"}
:::
:::

## Lyrics

::: columns
::: {.column width="50%"}
-   [Genius API using geniusr R package](analysis/genius_api.html)
:::

::: {.column width="50%"}
![](imgs/Genius.jpeg){fig-align="center" width="320"}
:::
:::

## Combined DF

```{r}
#| output-location: column-fragment

library(tidyverse)

read_csv('data/lyr_df.csv') |> 
    arrange(song) |> 
    head(20)
```





:::
## Natural Language Processing

[**Text mining**](analysis/text_mining.html) to clean and organize the lyrics into analyzable data

```{r}
library(tidytext)
#| results: asis

song_lyrics <- read_csv('data/lyr_df.csv')
song_lyrics |> 
  unnest_tokens(word, lyrics) |> 
  anti_join(get_stopwords()) |> 
  count(genre, word, sort = TRUE) |> 
  group_by(genre) |> 
  slice_max(n, n = 15) |> 
  ungroup() |> 
  mutate(word = reorder_within(word, n, genre)) |> 
  ggplot(aes(n, word, fill = genre)) +
  geom_col(show.legend = FALSE) +
  scale_y_reordered() +
    scale_fill_manual(values = clrs)+
  facet_wrap(~genre, scales = "free") +
  labs(
    x = "Word frequency", y = NULL,
    title = "Top words in song lyrics by frequency",
    subtitle = "After removing stop words"
  ) +
    theme_ben()


song_lyrics |> 
  unnest_tokens(trigram, lyrics, token = 'ngrams', n = 3) |> 
  count(genre, trigram, sort = TRUE) |> 
  group_by(genre) |> 
  slice_max(n, n = 15) |> 
  ungroup() |> 
  mutate(trigram = reorder_within(trigram, n, genre)) |> 
  ggplot(aes(n, trigram, fill = genre)) +
  geom_col(show.legend = FALSE) +
  scale_y_reordered() +
    
    scale_fill_manual(values = clrs)+
  facet_wrap(~genre, scales = "free") +
  labs(
    x = "Word frequency", y = NULL,
    title = "Top trigrams in song lyrics by frequency",
    subtitle = "After removing stop words"
  ) +
    theme_ben()


```

```{r eval=FALSE}

genre_words <- song_lyrics |>
    mutate(lyrics = lyrics |> str_replace("nigga", 'nxxxx')) |>
    unnest_tokens(word, lyrics)|>
    add_count(genre, name = "total_words") |> 
    group_by(genre, total_words) |> 
    count(word, sort = TRUE) |> 
    ungroup()

genre_words_tf_idf <- genre_words |> 
    select(-total_words) |>
    bind_tf_idf(term = word, document = genre, n = n)
    

#song_words_tf_idf |> write_csv('../data/song_words_tf_idf.csv')

genre_words_tf_idf |> 
    arrange(desc(tf_idf)) |> 
    head(10) |> 
    ggplot(aes(x = tf_idf,
               y = reorder(word, n), 
               label = word, 
               fill = genre)) +
    geom_col() +
    geom_label(fill = 'white')  +
    # ylab('Song - Artist') +
    xlab('TF-IDF Score')+
   # theme_ipsum_ps()
     theme_ben()+
  scale_fill_manual(values = clrs) 

genre_words_tf_idf |> 
    # select(-song, -hip_hop_rnb,-genre) |> 
    arrange(desc(tf_idf))  |> head(30) |> 
    theme_table()
```

## Tokenization

-   [**TF-IDF**](analysis/tfidf.html) to determine which words in each song separates that song from others

## Exploratory Data Analysis

# Machine Learning {.sectionhead}

## Principle Component Analysis (PCA)

-   Use neural networks models to classify songs based on TF-IDF scores

## Naive Bayes Classification

:::{.tabset}

### Model 1
```{python eval=FALSE, echo=TRUE}
import pandas as pd
import numpy as np

song_lyrics = pd.read_csv('data/lyr_df.csv')
song_lyrics.head(10)

from sklearn.utils import shuffle
from nltk.corpus import stopwords

genres = [
    'Country / Rock','Hip Hop / R&B'
]
genres

LYRIC_LEN = 400 # each song has to be > 400 characters
N = 300 # number of records to pull from each genre
RANDOM_SEED = 200 # random seed to make results repeatable

train_df = pd.DataFrame()
test_df = pd.DataFrame()
for genre in genres: # loop over each genre
    subset = song_lyrics[ # create a subset 
        (song_lyrics.genre==genre) & 
        (song_lyrics.lyrics.str.len() > LYRIC_LEN)
    ]
    train_set = subset.sample(n=N, random_state=RANDOM_SEED)
    test_set = subset.drop(train_set.index)
    train_df = train_df.append(train_set) # append subsets to the master sets
    test_df = test_df.append(test_set)
    
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline

# define our model
text_clf = Pipeline(
    [('vect', CountVectorizer()),
     ('clf', MultinomialNB(alpha=0.1))])

# train our model on training data
text_clf.fit(train_df.lyrics, train_df.genre)  

# score our model on testing data
predicted = text_clf.predict(test_df.lyrics)
np.mean(predicted == test_df.genre)

```

### Model 2
```{python eval=FALSE,  echo=TRUE}
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer

# define our model
text_clf = Pipeline(
    [('vect', TfidfVectorizer()),
     ('clf', MultinomialNB(alpha=0.1))])

# train our model on training data
text_clf.fit(train_df.lyrics, train_df.genre)  

# score our model on testing data
predicted = text_clf.predict(test_df.lyrics)
np.mean(predicted == test_df.genre)

```

### Model 3
```{python eval=FALSE,  echo=TRUE}

from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from nltk import word_tokenize
from nltk.stem import WordNetLemmatizer

stop = list(set(stopwords.words('english'))) # stopwords
wnl = WordNetLemmatizer() # lemmatizer

def tokenizer(x): # custom tokenizer
    return (
        wnl.lemmatize(w) 
        for w in word_tokenize(x) 
        if len(w) > 2 and w.isalnum() # only words that are > 2 characters
    )                                 # and is alpha-numeric

# define our model
text_clf = Pipeline(
    [('vect', TfidfVectorizer(
        ngram_range=(1, 2), # include bigrams
        tokenizer=tokenizer,
        stop_words=stop,
        max_df=0.4, # ignore terms that appear in more than 40% of documents
        min_df=4)), # ignore terms that appear in less than 4 documents
     ('tfidf', TfidfTransformer()),
     ('clf', MultinomialNB(alpha=0.1))])

# train our model on training data
text_clf.fit(train_df.lyrics, train_df.genre)  

# score our model on testing data
predicted = text_clf.predict(test_df.lyrics)
np.mean(predicted == test_df.genre)
```
:::







# Discussion {.sectionhead}

## Limitations

-   Language -- Lexicons used in/for stopwords, lemmatization, stemming, etc. not based on AAVE.

-   Context -- Music, hip hop in particular, uses a lot of figurative language and words often have more than one meaning.

-   Stopwords, non-stop -- Between ad-libs and harmonizing, a lot of lyrics add no meaning.
