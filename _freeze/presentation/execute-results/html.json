{
  "hash": "0bc3bef31db7412a6e2df22c1988256a",
  "result": {
    "markdown": "---\ntitle: \"HipHop ML\"\ntitle-slide-attributes:\n    data-background-image: imgs/hip-hop.png\n    data-background-size: cover\n    data-background-opacity: \"0.5\"\nauthor: \"def jam()\"\ndate: 'Mar 7, 2023'\nformat: \n    revealjs:\n        theme: [dark, custom.scss]\n        toc: false\nexecute: \n  echo: false\n  warning: false\n  freeze: true\n  \nfrom: markdown+emoji\n---\n\n\n# Introduction {.sectionhead style=\"color:#222222\"}\n\n\n::: {.cell}\n\n:::\n\n\n## Artists / Producers\n\n:radio: DJ [Joan]{.red} Adebowale\n\n:musical_score: Lil [Marquesia]{.red} Atwater\n\n:microphone: MC [Tesa]{.red} Childs-Skelton\n\n:cd: Grand Master [Sorie]{.red} Dumbuya\n\n:speaker: Ol' Dirty [Marcus]{.red} Gibson\n\n## Tracklist {background-image=\"imgs/vinyl.jpg\" background-size=\"cover\"}\n\n::: {.column .li_item width=\"80%\"}\n-   [Overview]{.red} -- Ol Dirty Marcus\n-   [Data Processing]{.red} -- MC Tesa\n-   [Machine Learning]{.red} -- DJ Joan feat. Grandmaster Sorie\n-   [Discussion]{.red} -- Lil Marquesia\n-   [Round of Applause]{.red} -- GT Bootcamp 2023 Cohort\n:::\n\n## Overview\n\n-   In 2023, Hip hop will celebrate [the 50th anniversary](https://the50thanniversaryofhip-hop.com/){target=\"_blank\"} of its founding.\n\n-   Originated in the West Bronx, it has become a billion dollar industry and [the most popular music genre in the US](https://www.billboard.com/music/music-news/billboard-explains-rb-hip-hop-biggest-genre-9613422/#!).\n\n## Challenge\n\n-  Using machine learning methods and lyrics retrieved via the Genius API, we’re identifying whether a song is considered hip hop and R&B  based on the lyrics.\n\n# Data Processing {.sectionhead style=\"color:#222222\"}\n\n## Data Sources\n\n::: panel-tabset\n## Songs\n\n::: columns\n::: {.column width=\"50%\"}\n[Scraped Wikipedia pages](analysis/rnb_wiki_scrapper.html) for Billboard's #1 Songs from 1989-2019 for:\n\n-   Country\n\n-   Hip hop\n\n-   RnB\n\n-   Rock\n:::\n\n::: {.column width=\"50%\"}\n![](imgs/wiki.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::\n\n## Database\n\n::: columns\n::: {.column width=\"50%\"}\n![](imgs/rds.png){fig-align=\"center\" width=\"100%\"}\n:::\n\n::: {.column width=\"50%\"}\n![](imgs/table.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::\n\n## Lyrics\n\n::: columns\n::: {.column width=\"50%\"}\n-   [Genius API using geniusr R package](analysis/genius_api.html)\n:::\n\n::: {.column width=\"50%\"}\n![](imgs/Genius.jpeg){fig-align=\"center\" width=\"320\"}\n:::\n:::\n\n## Combined DF\n\n\n::: {.cell output-location='column-fragment'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 20 × 5\n   song                                           artist    hip_h…¹ lyrics genre\n   <chr>                                          <chr>       <dbl> <chr>  <chr>\n 1 (If You're Not in It for Love) I'm Outta Here! Shania T…       0 \"Thre… Coun…\n 2 (This Ain't) No Thinkin' Thing                 Trace Ad…       0 \"I be… Coun…\n 3 1000hp                                         Godsmack        0 \"Time… Coun…\n 4 16                                             Highly S…       0 \"It t… Coun…\n 5 21 Questions                                   50 Cent         1 \"New … Hip …\n 6 911 Is a Joke                                  Public E…       1 \"Hit … Hip …\n 7 A Better Man                                   Clint Bl…       0 \"What… Coun…\n 8 A Broken Wing                                  Martina …       0 \"She … Coun…\n 9 A Good Run of Bad Luck                         Clint Bl…       0 \"A hi… Coun…\n10 A Guy Walks Into a Bar                         Tyler Fa…       0 \"The … Coun…\n11 A Guy with a Girl                              Blake Sh…       0 \"Some… Coun…\n12 A Jukebox with a Country Song                  Doug Sto…       0 \"Afte… Coun…\n13 A Little Bit Stronger                          Sara Eva…       0 \"Woke… Coun…\n14 A Little More Country Than That                Easton C…       0 \"Imag… Coun…\n15 A Man This Lonely                              Brooks &…       0 \"A ma… Coun…\n16 A Milli                                        Lil Wayne       1 \"Bang… Hip …\n17 A Real Fine Place to Start                     Sara Eva…       0 \"I'm … Coun…\n18 A Reason to Fight                              Disturbed       0 \"The … Coun…\n19 A Song for Mama                                Boyz II …       1 \"You … Hip …\n20 A Woman in Love                                Ronnie M…       0 \"No m… Coun…\n# … with abbreviated variable name ¹​hip_hop_rnb\n```\n:::\n:::\n\n:::\n\n## Natural Language Processing\n\n[**Text mining**](analysis/text_mining.html) to clean and organize the lyrics into analyzable data\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-3-2.png){width=960}\n:::\n:::\n\n\n# Machine Learning {.sectionhead}\n\n## Principle Component Analysis (PCA)\n\n::: panel-tabset\n### Data Prep\n\n![](imgs/prep.png){fig-align=\"center\" width=\"320\"} \\### Results ![](imgs/analysis%201.png){fig-align=\"center\" width=\"320\"} \\### Results ![](imgs/analysis%202.png){fig-align=\"center\" width=\"320\"}\n:::\n\n## Naive Bayes Classification\n\n::: columns\n::: {.column width=\"70%\"}\n::: panel-tabset\n### Model 1\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\nsong_lyrics = pd.read_csv('data/lyr_df.csv')\nsong_lyrics.head(10)\n\nfrom sklearn.utils import shuffle\nfrom nltk.corpus import stopwords\n\ngenres = [\n    'Country / Rock','Hip Hop / R&B'\n]\ngenres\n\nLYRIC_LEN = 400 # each song has to be > 400 characters\nN = 300 # number of records to pull from each genre\nRANDOM_SEED = 200 # random seed to make results repeatable\n\ntrain_df = pd.DataFrame()\ntest_df = pd.DataFrame()\nfor genre in genres: # loop over each genre\n    subset = song_lyrics[ # create a subset \n        (song_lyrics.genre==genre) & \n        (song_lyrics.lyrics.str.len() > LYRIC_LEN)\n    ]\n    train_set = subset.sample(n=N, random_state=RANDOM_SEED)\n    test_set = subset.drop(train_set.index)\n    train_df = train_df.append(train_set) # append subsets to the master sets\n    test_df = test_df.append(test_set)\n    \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\n\n# define our model\ntext_clf = Pipeline(\n    [('vect', CountVectorizer()),\n     ('clf', MultinomialNB(alpha=0.1))])\n\n# train our model on training data\ntext_clf.fit(train_df.lyrics, train_df.genre)  \n\n# score our model on testing data\npredicted = text_clf.predict(test_df.lyrics)\nnp.mean(predicted == test_df.genre)\n```\n:::\n\n\n### Model 2\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n\n# define our model\ntext_clf = Pipeline(\n    [('vect', TfidfVectorizer()),\n     ('clf', MultinomialNB(alpha=0.1))])\n\n# train our model on training data\ntext_clf.fit(train_df.lyrics, train_df.genre)  \n\n# score our model on testing data\npredicted = text_clf.predict(test_df.lyrics)\nnp.mean(predicted == test_df.genre)\n```\n:::\n\n\n### Model 3\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nstop = list(set(stopwords.words('english'))) # stopwords\nwnl = WordNetLemmatizer() # lemmatizer\n\ndef tokenizer(x): # custom tokenizer\n    return (\n        wnl.lemmatize(w) \n        for w in word_tokenize(x) \n        if len(w) > 2 and w.isalnum() # only words that are > 2 characters\n    )                                 # and is alpha-numeric\n\n# define our model\ntext_clf = Pipeline(\n    [('vect', TfidfVectorizer(\n        ngram_range=(1, 2), # include bigrams\n        tokenizer=tokenizer,\n        stop_words=stop,\n        max_df=0.4, # ignore terms that appear in more than 40% of documents\n        min_df=4)), # ignore terms that appear in less than 4 documents\n     ('tfidf', TfidfTransformer()),\n     ('clf', MultinomialNB(alpha=0.1))])\n\n# train our model on training data\ntext_clf.fit(train_df.lyrics, train_df.genre)  \n\n# score our model on testing data\npredicted = text_clf.predict(test_df.lyrics)\nnp.mean(predicted == test_df.genre)\n```\n:::\n\n:::\n:::\n\n::: {.column width=\"30%\"}\n| Model | Results |\n|-------|---------|\n| 1     | 0.90252 |\n| 2     | 0.91038 |\n| 3     | 0.83334 |\n:::\n:::\n\n## Support Vector Machine\n\n::: panel-tabset\n\n###  Model\n\n\n::: {.cell output-location='column-fragment'}\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(tidymodels)\nlibrary(textrecipes)\nlibrary(themis)\n\nset.seed(50)\nlyrics_split <- song_lyrics |> \n  select(genre, lyrics) |> \n  initial_split(strata = genre)\n\nlyrics_train <- training(lyrics_split)\nlyrics_test <- testing(lyrics_split)\n\nset.seed(23)\nlyrics_folds <- vfold_cv(lyrics_train, strata = genre)\n\n\nlyrics_rec <- recipe(genre ~ lyrics, data = lyrics_train) %>%\n  step_tokenize(lyrics) |> \n  step_tokenfilter(lyrics, max_tokens = 1e3) |> \n  step_tfidf(lyrics) |> \n  step_normalize(all_numeric_predictors()) |> \n  step_smote(genre)\n\nlyrics_rec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          1\n\nOperations:\n\nTokenization for lyrics\nText filtering for lyrics\nTerm frequency-inverse document frequency with lyrics\nCentering and scaling for all_numeric_predictors()\nSMOTE based on genre\n```\n:::\n:::\n\n\n### Pipeline / Recipe\n\n\n::: {.cell output-location='column-fragment'}\n\n```{.r .cell-code}\nsvm_spec <- svm_linear() %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"LiblineaR\")\n\nlyrics_wf <- workflow() %>%\n  add_recipe(lyrics_rec) %>%\n  add_model(svm_spec)\n\ndoParallel::registerDoParallel()\nset.seed(123)\nsvm_rs <- fit_resamples(\n  lyrics_wf,\n  lyrics_folds,\n  metrics = metric_set(accuracy, recall, precision),\n  control = control_resamples(save_pred = TRUE)\n)\n\ncollect_metrics(svm_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 6\n  .metric   .estimator  mean     n std_err .config             \n  <chr>     <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy  binary     0.811    10  0.0100 Preprocessor1_Model1\n2 precision binary     0.881    10  0.0108 Preprocessor1_Model1\n3 recall    binary     0.821    10  0.0101 Preprocessor1_Model1\n```\n:::\n:::\n\n\n### Plot\n\n\n::: {.cell output-location='column-fragment'}\n\n```{.r .cell-code}\nsvm_rs |> \n  conf_mat_resampled(tidy = FALSE) |> \n  autoplot() \n```\n\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n### Performance\n\n\n::: {.cell output-location='column-fragment'}\n\n```{.r .cell-code}\nfinal_fitted <- last_fit(\n  lyrics_wf,\n  lyrics_split,\n  metrics = metric_set(accuracy, recall, precision)\n)\ncollect_metrics(final_fitted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  .metric   .estimator .estimate .config             \n  <chr>     <chr>          <dbl> <chr>               \n1 accuracy  binary         0.781 Preprocessor1_Model1\n2 recall    binary         0.801 Preprocessor1_Model1\n3 precision binary         0.854 Preprocessor1_Model1\n```\n:::\n:::\n\n:::\n\n# Discussion {.sectionhead}\n\n## Limitations\n\nThe main limitations we encountered includes context and nonstop words.\n- The context of certain words had double meaning.\n- When we approached the non stop words like “yea yea yea” we realized they were included as ad-libs so they had no meaning.\n- In the future we will go towards a better analysis and algorithm.\n- Also what would help is building our own non stop words and create dictionaries so the machine learning could distinguish those words as lyrics\n\n-   Stopwords, non-stop -- Between ad-libs and harmonizing, a lot of lyrics add no meaning.\n",
    "supporting": [
      "presentation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}