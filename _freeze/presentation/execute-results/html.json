{
  "hash": "0cedc478c27ae84bb35e53c4efe226b2",
  "result": {
    "markdown": "---\ntitle: \"HipHop ML\"\ntitle-slide-attributes:\n    data-background-image: /imgs/hip-hop.png\n    data-background-size: cover\n    data-background-opacity: \"0.5\"\nauthor: \"def jam()\"\ndate: 'Mar 7, 2023'\nformat: \n    revealjs:\n        theme: [dark, custom.scss]\n        toc: false\nexecute: \n  echo: false\n  warning: false\n  freeze: true\n  \nfrom: markdown+emoji\n---\n\n\n# Introduction {.sectionhead style=\"color:#222222\"}\n\n\n::: {.cell}\n\n:::\n\n\n## Producers\n\n:radio: DJ [Joan]{.red} Adebowale\n\n:musical_score: Lil [Marquesia]{.red} Atwater\n\n:microphone: MC [Tesa]{.red} Childs-Skelton\n\n:cd: Grand Master [Sorie]{.red} Dumbuya\n\n:speaker: Ol' Dirty [Marcus]{.red} Gibson\n\n## Tracklist {background-image=\"imgs/vinyl.jpg\" background-size=\"cover\"}\n\n::: {.column .li_item width=\"80%\"}\n-   [Overview]{.red} -- Ol Dirty Marcus\n-   [Data Processing]{.red} -- MC Tesa\n-   [Machine Learning]{.red} -- Grandmaster Sorie\n-   [Discussion]{.red} -- DJ Joan feat. Lil Marquesia\n-   [Round of Applause]{.red} -- GT Bootcamp 2023 Cohort\n:::\n\n## Overview\n\n-   In 2023, Hip hop will celebrate [the 50th anniversary](https://the50thanniversaryofhip-hop.com/){target=\"_blank\"} of its founding by Brooklyn youth.\n\n-   Since then, it has become a billion dollar industry and [the most popular music genre in the US](https://www.billboard.com/music/music-news/billboard-explains-rb-hip-hop-biggest-genre-9613422/#!).\n\n## Challenge\n\n-   Using machine learning and lyrics retrieved via the Genius API to identify songs hip hop and RnB based on lyrics\n\n# Data Processing {.sectionhead style=\"color:#222222\"}\n\n## Data Sources\n\n::: panel-tabset\n## Songs\n\n::: columns\n::: {.column width=\"50%\"}\n[Scraped Wikipedia pages](analysis/rnb_wiki_scrapper.html) for Billboard's #1 Songs from 1989-2019 for:\n\n-   Country\n\n-   Hip hop\n\n-   RnB\n\n-   Rock\n:::\n\n::: {.column width=\"50%\"}\n![](imgs/wiki.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::\n\n## Database\n\n::: columns\n::: {.column width=\"50%\"}\n![](imgs/rds.png){fig-align=\"center\" width=\"100%\"}\n\n:::\n\n::: {.column width=\"50%\"}\n![](imgs/table.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::\n\n## Lyrics\n\n::: columns\n::: {.column width=\"50%\"}\n-   [Genius API using geniusr R package](analysis/genius_api.html)\n:::\n\n::: {.column width=\"50%\"}\n![](imgs/Genius.jpeg){fig-align=\"center\" width=\"320\"}\n:::\n:::\n\n## Combined DF\n\n\n::: {.cell output-location='column-fragment'}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 20 × 5\n   song                                           artist    hip_h…¹ lyrics genre\n   <chr>                                          <chr>       <dbl> <chr>  <chr>\n 1 (If You're Not in It for Love) I'm Outta Here! Shania T…       0 \"Thre… Coun…\n 2 (This Ain't) No Thinkin' Thing                 Trace Ad…       0 \"I be… Coun…\n 3 1000hp                                         Godsmack        0 \"Time… Coun…\n 4 16                                             Highly S…       0 \"It t… Coun…\n 5 21 Questions                                   50 Cent         1 \"New … Hip …\n 6 911 Is a Joke                                  Public E…       1 \"Hit … Hip …\n 7 A Better Man                                   Clint Bl…       0 \"What… Coun…\n 8 A Broken Wing                                  Martina …       0 \"She … Coun…\n 9 A Good Run of Bad Luck                         Clint Bl…       0 \"A hi… Coun…\n10 A Guy Walks Into a Bar                         Tyler Fa…       0 \"The … Coun…\n11 A Guy with a Girl                              Blake Sh…       0 \"Some… Coun…\n12 A Jukebox with a Country Song                  Doug Sto…       0 \"Afte… Coun…\n13 A Little Bit Stronger                          Sara Eva…       0 \"Woke… Coun…\n14 A Little More Country Than That                Easton C…       0 \"Imag… Coun…\n15 A Man This Lonely                              Brooks &…       0 \"A ma… Coun…\n16 A Milli                                        Lil Wayne       1 \"Bang… Hip …\n17 A Real Fine Place to Start                     Sara Eva…       0 \"I'm … Coun…\n18 A Reason to Fight                              Disturbed       0 \"The … Coun…\n19 A Song for Mama                                Boyz II …       1 \"You … Hip …\n20 A Woman in Love                                Ronnie M…       0 \"No m… Coun…\n# … with abbreviated variable name ¹​hip_hop_rnb\n```\n:::\n:::\n\n\n\n\n\n\n:::\n## Natural Language Processing\n\n[**Text mining**](analysis/text_mining.html) to clean and organize the lyrics into analyzable data\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n\n::: {.cell-output-display}\n![](presentation_files/figure-revealjs/unnamed-chunk-3-2.png){width=960}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n## Tokenization\n\n-   [**TF-IDF**](analysis/tfidf.html) to determine which words in each song separates that song from others\n\n## Exploratory Data Analysis\n\n# Machine Learning {.sectionhead}\n\n## Principle Component Analysis (PCA)\n\n-   Use neural networks models to classify songs based on TF-IDF scores\n\n## Naive Bayes Classification\n\n::: panel-tabset\n\n### Model 1\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\n\nsong_lyrics = pd.read_csv('data/lyr_df.csv')\nsong_lyrics.head(10)\n\nfrom sklearn.utils import shuffle\nfrom nltk.corpus import stopwords\n\ngenres = [\n    'Country / Rock','Hip Hop / R&B'\n]\ngenres\n\nLYRIC_LEN = 400 # each song has to be > 400 characters\nN = 300 # number of records to pull from each genre\nRANDOM_SEED = 200 # random seed to make results repeatable\n\ntrain_df = pd.DataFrame()\ntest_df = pd.DataFrame()\nfor genre in genres: # loop over each genre\n    subset = song_lyrics[ # create a subset \n        (song_lyrics.genre==genre) & \n        (song_lyrics.lyrics.str.len() > LYRIC_LEN)\n    ]\n    train_set = subset.sample(n=N, random_state=RANDOM_SEED)\n    test_set = subset.drop(train_set.index)\n    train_df = train_df.append(train_set) # append subsets to the master sets\n    test_df = test_df.append(test_set)\n    \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\n\n# define our model\ntext_clf = Pipeline(\n    [('vect', CountVectorizer()),\n     ('clf', MultinomialNB(alpha=0.1))])\n\n# train our model on training data\ntext_clf.fit(train_df.lyrics, train_df.genre)  \n\n# score our model on testing data\npredicted = text_clf.predict(test_df.lyrics)\nnp.mean(predicted == test_df.genre)\n```\n:::\n\n\n### Model 2\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n\n# define our model\ntext_clf = Pipeline(\n    [('vect', TfidfVectorizer()),\n     ('clf', MultinomialNB(alpha=0.1))])\n\n# train our model on training data\ntext_clf.fit(train_df.lyrics, train_df.genre)  \n\n# score our model on testing data\npredicted = text_clf.predict(test_df.lyrics)\nnp.mean(predicted == test_df.genre)\n```\n:::\n\n\n### Model 3\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom nltk import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nstop = list(set(stopwords.words('english'))) # stopwords\nwnl = WordNetLemmatizer() # lemmatizer\n\ndef tokenizer(x): # custom tokenizer\n    return (\n        wnl.lemmatize(w) \n        for w in word_tokenize(x) \n        if len(w) > 2 and w.isalnum() # only words that are > 2 characters\n    )                                 # and is alpha-numeric\n\n# define our model\ntext_clf = Pipeline(\n    [('vect', TfidfVectorizer(\n        ngram_range=(1, 2), # include bigrams\n        tokenizer=tokenizer,\n        stop_words=stop,\n        max_df=0.4, # ignore terms that appear in more than 40% of documents\n        min_df=4)), # ignore terms that appear in less than 4 documents\n     ('tfidf', TfidfTransformer()),\n     ('clf', MultinomialNB(alpha=0.1))])\n\n# train our model on training data\ntext_clf.fit(train_df.lyrics, train_df.genre)  \n\n# score our model on testing data\npredicted = text_clf.predict(test_df.lyrics)\nnp.mean(predicted == test_df.genre)\n```\n:::\n\n:::\n\n\n\n\n\n\n\n# Discussion {.sectionhead}\n\n## Limitations\n\n-   Language -- Lexicons used in/for stopwords, lemmatization, stemming, etc. not based on AAVE.\n\n-   Context -- Music, hip hop in particular, uses a lot of figurative language and words often have more than one meaning.\n\n-   Stopwords, non-stop -- Between ad-libs and harmonizing, a lot of lyrics add no meaning.\n",
    "supporting": [
      "presentation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n\r\n      // dispatch for htmlwidgets\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for reveal\r\n    if (window.Reveal) {\r\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\r\n        fireSlideChanged(event.previousSlide, event.currentSlide);\r\n      });\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}